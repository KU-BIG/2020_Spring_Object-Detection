{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Instagram Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium_requests_html==1.0\n",
    "# !pip install requests_html\n",
    "# #after downloading, you need to restart the kernal.\n",
    "# !pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from seleniumrequestshtml import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import urllib.request\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "def scroll_down(webdriver):\n",
    "    webdriver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(3)\n",
    "\n",
    "def add_photo(webdriver) :\n",
    "    temp_list = []\n",
    "    one_photo = webdriver.find_elements_by_class_name(\"FFVAD\")\n",
    "    for n in one_photo:\n",
    "        temp = n.get_attribute('src')\n",
    "        temp_list.append(temp)\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.17763.1217]\r\n",
      "(c) 2018 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(base) C:\\Users\\gudtj\\Desktop>cd models/research/\n",
      "\r\n",
      "(base) C:\\Users\\gudtj\\Desktop\\models\\research>protoc object_detection/protos/*.proto --python_out=.\n",
      "\r\n",
      "(base) C:\\Users\\gudtj\\Desktop\\models\\research>"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\r\n"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Windows [Version 10.0.17763.1217]\r\n",
      "(c) 2018 Microsoft Corporation. All rights reserved.\r\n",
      "\r\n",
      "(base) C:\\Users\\gudtj\\Desktop>cd models/research\n",
      "\r\n",
      "(base) C:\\Users\\gudtj\\Desktop\\models\\research>pip install .\n",
      "Processing c:\\users\\gudtj\\desktop\\models\\research\r\n",
      "Requirement already satisfied: Pillow>=1.0 in c:\\users\\gudtj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from object-detection==0.1) (5.4.1)\r\n",
      "Requirement already satisfied: Matplotlib>=2.1 in c:\\users\\gudtj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from object-detection==0.1) (3.0.3)\r\n",
      "Requirement already satisfied: Cython>=0.28.1 in c:\\users\\gudtj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from object-detection==0.1) (0.29.6)\r\n",
      "Requirement already satisfied: numpy>=1.10.0 in c:\\users\\gudtj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Matplotlib>=2.1->object-detection==0.1) (1.16.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gudtj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Matplotlib>=2.1->object-detection==0.1) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gudtj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Matplotlib>=2.1->object-detection==0.1) (1.0.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\gudtj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Matplotlib>=2.1->object-detection==0.1) (2.3.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\gudtj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Matplotlib>=2.1->object-detection==0.1) (2.8.0)\r\n",
      "Requirement already satisfied: six in c:\\users\\gudtj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cycler>=0.10->Matplotlib>=2.1->object-detection==0.1) (1.12.0)\r\n",
      "Requirement already satisfied: setuptools in c:\\users\\gudtj\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->Matplotlib>=2.1->object-detection==0.1) (46.1.3)\r\n",
      "Building wheels for collected packages: object-detection\r\n",
      "  Building wheel for object-detection (setup.py): started\r\n",
      "  Building wheel for object-detection (setup.py): finished with status 'done'\r\n",
      "  Stored in directory: C:\\Users\\gudtj\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-k44dc88r\\wheels\\43\\61\\30\\be2a1f5806905b1b281a5761213863af200c438e74565222b0\r\n",
      "Successfully built object-detection\r\n",
      "Installing collected packages: object-detection\r\n",
      "  Found existing installation: object-detection 0.1\r\n",
      "    Uninstalling object-detection-0.1:\r\n",
      "      Successfully uninstalled object-detection-0.1\r\n",
      "Successfully installed object-detection-0.1\r\n",
      "\r\n",
      "(base) C:\\Users\\gudtj\\Desktop\\models\\research>"
     ]
    }
   ],
   "source": [
    "%%cmd\n",
    "cd models/research\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch tf1 into `utils.ops`\n",
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "# Patch the location of gfile\n",
    "tf.gfile = tf.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "    model_file = model_name + '.tar.gz'\n",
    "    model_dir = tf.keras.utils.get_file(\n",
    "    fname=model_name, \n",
    "    origin=base_url + model_file,\n",
    "    untar=True)\n",
    "\n",
    "    model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "\n",
    "    model = tf.saved_model.load(str(model_dir))\n",
    "    model = model.signatures['serving_default']\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = 'models/research/object_detection/data/oid_v4_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('models/research/object_detection/test_images/image1.jpg'),\n",
       " WindowsPath('models/research/object_detection/test_images/image2.jpg')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model_name = 'faster_rcnn_inception_resnet_v2_atrous_oid_v4_2018_12_12'\n",
    "detection_model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "    image = np.asarray(image)\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    output_dict = model(input_tensor)\n",
    "\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "\n",
    "    if 'detection_masks' in output_dict:\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                  output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "                   image.shape[0], image.shape[1])      \n",
    "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                           tf.uint8)\n",
    "        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_inference_url_list(model, url_list):\n",
    "    \n",
    "    label_list = []\n",
    "\n",
    "    for image_url in url_list:\n",
    "    \n",
    "        response = requests.get(image_url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        image_np = np.array(img)\n",
    "        output_dict = run_inference_for_single_image(model, image_np)\n",
    "        \n",
    "        result=[]\n",
    "        \n",
    "        for i in output_dict['detection_classes']:\n",
    "            result.append(category_index[i]['name'])\n",
    "            \n",
    "        label_list.append(result)\n",
    "    \n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import pickle\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/research/object_detection/glovetw.pickle','rb') as handle:\n",
    "    gl = pickle.load(handle)\n",
    "\n",
    "with open('models/research/object_detection/match.txt', 'r', encoding='UTF-8') as file:\n",
    "     match=json.load(file)\n",
    "        \n",
    "with open('models/research/object_detection/score.txt', 'r', encoding='UTF-8') as file:\n",
    "     score=json.load(file) \n",
    "        \n",
    "with open('models/research/object_detection/music.txt', 'r', encoding='UTF-8') as file:\n",
    "     music=json.load(file) \n",
    "\n",
    "evidences = list(score.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_feed(labels,evidences):\n",
    "    cnts = dict()\n",
    "    typescores=dict()\n",
    "    for label in labels:\n",
    "        mind=1000 \n",
    "        for e in evidences:\n",
    "            dist=float(np.sqrt(((gl[label.lower()]-gl[e])**2).sum()))\n",
    "#             print('distance between label {} & type {} : {}'.format(label,t,round(dist,2)))\n",
    "            if dist<mind:\n",
    "                mind=dist\n",
    "                closest=e\n",
    "        \n",
    "        typekey = ''.join([list(match.keys())[i] for i in range(len(match)) if closest in list(match.values())[i]])\n",
    "        \n",
    "        if typekey not in list(typescores.keys()):\n",
    "            typescores[typekey]=score[closest]\n",
    "        else:\n",
    "            typescores[typekey]+=score[closest]\n",
    "    return max(typescores.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "def getfeedcnts(labelists,evidences):\n",
    "    feedkeycnt=dict()\n",
    "    \n",
    "    #image_detection\n",
    "    for labels in labelists:\n",
    "        if labels==[]: continue;\n",
    "        labels=sum([t.split() for t in labels],[])\n",
    "        res = detect_feed(labels,evidences)\n",
    "        if res not in list(feedkeycnt.keys()):\n",
    "            feedkeycnt[res]=1\n",
    "        else:\n",
    "            feedkeycnt[res]+=1\n",
    "            \n",
    "    return feedkeycnt\n",
    "\n",
    "def main(labelists,evidences):\n",
    "    result=getfeedcnts(labelists,evidences)\n",
    "    print(result)\n",
    "    threshold=np.quantile(list(result.values()), .95) #cnt가 0.95분위수 이상인 keyword 두개 이상 존재 시 '살아있는 인스타그램'으로 분류\n",
    "    candidate=[r for r in list(result.keys()) if result[r]>threshold]\n",
    "    if len(candidate)==1:\n",
    "        return candidate[0]+'형'\n",
    "    else:\n",
    "        return '살아있는 인스타그램형'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Your Insta ID : a\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    877\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m                 \u001b[0mident\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\jupyter_client\\session.py\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m             \u001b[0mmsg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[1;34m(self, flags, copy, track)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \"\"\"\n\u001b[1;32m--> 470\u001b[1;33m         \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m         \u001b[1;31m# have first part already, only loop while more to receive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e4ba00b26d43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Insta Crawling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#검색을 원하는 insta ID\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0minsta_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input Your Insta ID : \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://www.instagram.com/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minsta_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m         )\n\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    881\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Insta Crawling\n",
    "#검색을 원하는 insta ID\n",
    "insta_id = input(\"Input Your Insta ID : \")  \n",
    "url = \"https://www.instagram.com/\" + insta_id\n",
    "\n",
    "webdriver = Chrome('models/research/object_detection/chromedriver.exe') # 경로 바꿔주세요!!!\n",
    "webdriver.get(url)\n",
    "session = webdriver.requests_session\n",
    "response = session.get(url)\n",
    "\n",
    "#포스트의 총 개수\n",
    "len_post = webdriver.find_element_by_class_name('g47SY').text\n",
    "\n",
    "photo_list = []\n",
    "try:\n",
    "    while True:\n",
    "        for n in add_photo(webdriver):\n",
    "            if n in photo_list:\n",
    "                pass\n",
    "            else:\n",
    "                photo_list.append(n)\n",
    "\n",
    "        scroll_down(webdriver)\n",
    "\n",
    "        if(int(len_post) == len(photo_list)):\n",
    "            break\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#Object Detection\n",
    "#상위 10개 사진만 하도록 설정. 밑에 숫자 조절 가능\n",
    "if len(photo_list) >= 10:\n",
    "    label_list = show_inference_url_list(detection_model, photo_list[0:10])\n",
    "else:\n",
    "    label_list = show_inference_url_list(detection_model, photo_list)\n",
    "\n",
    "#Word Embedding    \n",
    "type = main(label_list, evidences)\n",
    "musicmatch = random.sample(music[type], k=3)\n",
    "print(type, musicmatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예시\n",
    "\n",
    "혜진님: photo_list1  \n",
    "지혜님: photo_list2  \n",
    "정아님: photo_list3  \n",
    "형근님: photo_list4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Your Insta ID : basketlover63\n"
     ]
    }
   ],
   "source": [
    "#Insta Crawling\n",
    "#검색을 원하는 insta ID\n",
    "insta_id = input(\"Input Your Insta ID : \")  \n",
    "url = \"https://www.instagram.com/\" + insta_id\n",
    "\n",
    "webdriver = Chrome('models/research/object_detection/chromedriver.exe') # 경로 바꿔주세요!!!\n",
    "webdriver.get(url)\n",
    "session = webdriver.requests_session\n",
    "response = session.get(url)\n",
    "\n",
    "#포스트의 총 개수\n",
    "len_post = webdriver.find_element_by_class_name('g47SY').text\n",
    "\n",
    "photo_list5 = []\n",
    "try:\n",
    "    while True:\n",
    "        for n in add_photo(webdriver):\n",
    "            if n in photo_list5:\n",
    "                pass\n",
    "            else:\n",
    "                photo_list5.append(n)\n",
    "\n",
    "        scroll_down(webdriver)\n",
    "\n",
    "        if(int(len_post) == len(photo_list4)):\n",
    "            break\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list5 = show_inference_url_list(detection_model, photo_list5[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = main(label_list5, evidences)\n",
    "type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musicmatch = random.sample(music[type], k=3)\n",
    "musicmatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특정 사진에 대해 Object detection한 결과가 궁금할 때 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_inference_url(model, image_url):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    image_np = np.array(img)\n",
    "    output_dict = run_inference_for_single_image(model, image_np)\n",
    "\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=8)\n",
    "    print(output_dict['detection_classes'])\n",
    "    display(Image.fromarray(image_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_inference_url(detection_model, 'url 주소')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
